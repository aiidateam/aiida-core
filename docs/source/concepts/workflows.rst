.. _workflows:

*********
Workflows
*********

Workflows are a central concept in AiiDA that allow you to string together multiple calculations that encodes the logic of a typical scientific workflow.
In this section, we explain what workflows are, how they can be used and run.
Finally, we will detail some best practices when designing workflows.

.. _workchains_workfunctions:

Workchains and workfunctions
============================

At the core of a workflow, is the logic that defines the sequence of calculations that need to be executed to get from the initial inputs to the desired final answer.
The way to encode this workflow logic in AiiDA, are workchains and workfunctions.
By chaining workchains and workfunctions together, that each can run calculations within them, we can define a workflow.
For simplicity, from here on out, we will use the terms, workflows, workchains and workfunctions interchangeably, as a 'pars pro toto' and 'totum pro parte'.

Workfunctions
-------------
To illustrate how workfunctions and workchains are defined, how they are used and when to use which, we will consider the following trivial example.
Given three integers, sum the first two and then multiply the result by the third.
In plain python code, the solution would look something like the following:

.. include:: include/snippets/workflows/workfunctions/example_problem_plain_python.py
    :code: python

This simple code snippet achieved the goal of getting the desired result, however, the provenance is lost.
There is no connection between the output of the functions and their inputs.
The remedy to this problem is the ``workfunction``.
The ``workfunction`` in AiiDA is a decorator that transforms a regular python function in a workfunction, which automatically stores the provenance of its output.
The following snippet shows how little one has to change the initial solution to add automatic provenance keeping:

.. include:: include/snippets/workflows/workfunctions/example_problem_workfunction_decorator.py
    :code: python

The only thing we had to do is to decorate the two functions with the ``workfunction`` decorator.
Adding the decorator tells AiiDA that the provenance for this function when it is executed should be stored.
This means linking up the inputs and the outputs for a calculation node, which represents the function that was executed.
The final change that has to be performed is to make the inputs and the outputs storable.
In this example, they are plain python integer types, which cannot be stored in the database.
To solve this, one only has to wrap them in the ``Int`` class, which makes them storable in the database:

.. include:: include/snippets/workflows/workfunctions/example_problem_workfunction_data_types.py
    :code: python

The only difference with the previous snippet is that all inputs and outputs have been wrapped in the ``Int`` class.
With these trivial changes, the full provenance of the result is maintained and looks like this:

.. figure:: include/images/workfunction_provenance.png

    The provenance generated by the workfunction example

To summarize: to write a workflow that automatically stores the provenance, one only has to decorate the functions with the ``workfunction`` decorator and make sure that the inputs and outputs are wrapped in database storable types.

Workchains
----------
Now that we have demonstrated how easily ``workfunctions`` can be used to write your workflow that automatically keeps the provenance, it is time to confess that workfunctions are not perfect and have their shortcomings.
In the simple example of adding and multiplying numbers, the time to execute the functions is very short, but imagine that you are performing a more costly calculation, e.g. you want to run an actual ``JobCalculation`` that will be submitted to the scheduler and may run for a long time.
If anywhere during the chain, the workflow is interrupted, for whatever reason, all progress is lost.
There are no 'checkpoints', so to speak, by simply chaining workfunctions together.

But fret not!
To tackle this problem, AiiDA defines the concept of the workchain.
As the name suggests, this construct is a way to chain multiple logical steps of a workflow together in a way that allows to save the progress between those steps as soon as they are successfully completed.
The workchain is therefore the preferred solution for parts of the workflow that involve more expensive and complex calculations.
To define a workchain, AiiDA implements the ``WorkChain`` class.

If we were to reimplement our workfunction solution of the simple example problem of the previous section, but this time using a workchain, it would look something like the following: 

.. include:: include/snippets/workflows/workchains/example_problem_workchain.py
    :code: python

There is a lot going on in this snippet, so let's tackle it line by line.
Firstly, a ``WorkChain`` is a class and to create your own workchain, you subclass it and give it your own name, like ``AddAndMultiplyWorkChain`` in the example.
You can pick any name that is a valid python class name.
The most important method of the ``WorkChain`` class, is the ``define`` class method.
Here you define, what inputs it takes, what outputs it will generate and the 'logic' that will be executed.
The class method takes two arguments:

 * ``cls`` this is the reference of the class itself and is mandatory for any class method
 * ``spec`` which is the 'specification'

.. note::
    Do not forget to add the line ``super(AddAndMultiplyWorkChain, self).define(spec)`` as the first line of the ``define`` method, where you replace the class name with the name of your workchain.
    This will call the ``define`` method of the parent class, which is necessary for the workchain to work properly

As the name suggests, the ``spec`` can be used to specify the properties of the workchain.
For example, it can be used to define inputs that the workchain takes.
In our example, we need to be able to pass three integers as input, so we define those in the spec by calling `spec.input()`.
The first argument is the name of the input.
Additionally, as we have done here, you can specify which types are valid for that particular input.
Since we expect integers, we specify that the valid type is the database storable ``Int`` class.
Input validation is just one of the advantages of the ``WorkChain`` over the workfunction that we can already see here.

The outputs are defined in a similar manner, calling `spec.output()` you can declare a particular output that the workchain will or is expected to have.
Be wary that if you define an output, but do not actually add it during the exection, at the end of the workchain, the validation will fail as by default all defined outputs are assumed to be required.
If you want to specify an output that is optional, you can pass the keyword argument ``required=False``.

The final part of the spec definition is the ``outline``.
This is where you specify the 'logic' of the workchain.
Since this example is rather contrived, in this case it is just a list of three functions calls ``add``, ``multiply`` and ``results``.
However, the outline also supports logical constructs, like ``if`` conditionals ``while`` loops and ``return`` statements.
Refer to the advanced :ref:`workchain section <process_spec>` to see all the possibilities the ``outline`` provides.

The only thing that remains, is to implement the methods that we added to the ``outline``.
Since they are class instance methods, they only take one argument ``self``.
Besides that rule, you can add any valid python code in the method that you want.
The goal of the ``add`` method is to take the inputs ``a`` and ``b`` that are passed to the workchain and sum them.
The inputs passed to the workchain are stored in the ``inputs`` attribute as an attribute dictionary.
Therefore, to get the ``a`` input for example, you can call ``self.inputs.a``.

After we summed ``a`` and ``b``, we need to be able to store the temporary result and pass it to the next step in the ``outline``, in this case the ``multiply`` method.
For this purpose, each workchain has a context, which can be addressed at ``self.ctx``.
It is a dictionary that is persisted between workchain steps and can therefore be used to pass information and data between outline steps.
Since it is a dictionary, we can store the sum of ``a`` and ``b`` by assigning it to a key of our choice.
Again, any valid python key name, as long as it does do not contain a period, is fair game.
Note that we do not have to return anything, as soon as the function ends, the workchain will save its state, including the result we just stored in the context and go to the next step, the ``multiply`` method.
By now you should be familiar with what you see.
We retrieve the sum we computed in the ``add`` method, multiply it by the ``c`` input integer and store it under the ``product`` key in the context.

The final step ``results`` adds the product as an official output of the workchain by calling ``self.out()``.
The first argument is the name of the output, which will also be used for the linkname in the provenance graph and the second argument is the actual value.
Note that since it again has to be database storable, we wrap the product in the ``Int`` class.
The resulting provenance when we run this workchain looks like this:

.. figure:: include/images/workchain_provenance.png

    The provenance generated by the workchain example

This is very quick overview of how a workchain works but of course it has a lot more features.
To learn how to write workchains for real life problems, continue reading at the :ref:`workflow development <workflow_development>` section.

When to use which
-----------------
Now that we know how the two workflow components, workflows and workchains, work in AiiDA, you might wonder: when should I use which one?
For simple operations that do not take long, the simplicity of the workfunction may be all you need, so by all means use it.
However, a good rule of thumb is that as soon as the code is expected to take longer, for example when you want to launch a ``JobCalculation``, it is always best to go for the ``WorkChain``.
The automatic checkpointing, which guarantess that work between steps is saved, becomes very important.
The workchain offers a lot more features than checkpointing that may make it more preferable over the workfunction, which you can read about in the :ref:`workflow development <workflow_development>` section.


.. _running_workflows:

Running workflows
=================

Run
---
Without realizing it, in the :ref:`introductory section on workfunctions and workchains <workchains_workfunctions>`, we already saw how a workfunction can be ran.
We can run a workfunction in exactly the same manner as you would run any other python function.
Simply call the function with the desired inputs and it will be executed, while AiiDA makes sure to store the provenance automatically in the background.
You can run workfunctions from anywhere, also inside an outline step of a workchain.

Running a ``WorkChain`` on the other hand, is slightly different.
Since it is a class, it cannot be 'run' directly like a function.
Instead, we have to 'launch' it.
This is done by passing it to the ``run`` function:

.. include:: include/snippets/workflows/workchains/run_workchain_keyword.py
    :code: python

As you can see, the ``run`` function can be imported from ``aiida.work.launch``.
To launch the workchain (in this example we use the ``AddAndMultiplyWorkChain`` from the previous section), we simply call the ``run`` function with the workchain as the first argument, followed by the inputs as keyword arguments.
Note that the keys used for each input have to correspond to the name of the inputs defined in the spec of the workchain.
One can also define the inputs in a dictionary and then use the standard python expansion method to automatically unwrap the dictionary into keyword arguments, as is shown here:

.. include:: include/snippets/workflows/workchains/run_workchain_expand.py
    :code: python

After the workchain's execution is finished, the result is returned, which is a dictionary of its outputs.
In this example the variable ``result`` will therefore be equal to ``{'result': 9}``.
If you would also like to get a reference of the node that represents the ``WorkChain`` in the database, one can use the ``run_get_node`` or ``run_get_pid`` functions: 

.. include:: include/snippets/workflows/workchains/run_workchain_get_node_pid.py
    :code: python

For the former, the ``node`` will be the ``WorkCalculation`` node that is used to represent the workchain in the database, whereas for the latter, the ``pid`` is the pk of that same node.

Submit
------
The launch functions, ``run``, ``run_get_node`` and ``run_get_pid``, described in the previous section, will execute the process in a blocking manner.
That is to say that the interpreter in which you launch the process will be blocked until that process is completed.
This might not necessarily be what you want.
Imagine for example that you are launching a workchain that will take a long time to complete.
The interpreter will be blocked the whole time and cannot do anything else.
To circumvent this problem, you can also ``submit`` a process, for example a workchain:

.. include:: include/snippets/workflows/workchains/run_workchain_submit.py
    :code: python

The ``submit`` function will launch the process and send it to the daemon, who will take care of running it to the end.
This way the interpreter is freed and regains control immediately.
The return value of the ``submit`` call is the node that represents the process in the database.
Note that besides the change in behavior, the syntax for passing the inputs to ``submit`` is exactly the same as for the ``run`` launch function and its siblings.

There is one limitation to the use of the ``run`` and ``submit`` launchers.
They cannot be used within the steps of a ``WorkChain`` itself.
Instead, the ``WorkChain`` class has its own ``submit`` method that should be used.

.. include:: include/snippets/workflows/workchains/run_workchain_submit_internal.py
    :code: python

In this example, we launch another instance of the ``AddAndMultiplyWorkChain`` from within the ``AddAndMultiplyWorkChain`` itself.
Note that the only difference is that instead of using the free function ``submit``, we use the class instance method ``self.submit``.

.. _running_workflows_process_builder:

Process builder
---------------
There is one final way of launching a process, whether it be a ``WorkChain`` or a ``JobCalculation``.
Each process has a method called ``get_builder`` which will return an instance of the ``ProcessBuilder`` customised for that particular ``Process`` class.
The builder knows exactly which inputs the process takes and expects and is therefore ideal for interactive usage.
For details on how to instantiate and populate a ``ProcessBuilder`` instance please refer to :ref:`the process builder section<process_builder>`.

One you have constructed your builder and inserted all the inputs, you can pass it to the launch functions like we did in the previous two sections:

.. include:: include/snippets/workflows/workchains/run_workchain_builder.py
    :code: python

Note that you are free to use this method of launching processes in normal scripts, but the builder really is designed for use in an interactive shell.


Monitoring workflows
====================

When you have launched workflows, be it workfunctions or workchains, you may want to investigate their status, progression and the results.

verdi work list
---------------
Your first point of entry will be the ``verdi`` command ``verdi work list``.
This command will print a list of all active ``WorkCalculation`` nodes, which are the database objects used by ``WorkChains`` and ``workfunctions`` to store the details of their execution in the database.
A typical example may look something like the following:

.. code-block:: bash

      PK  Creation    State           Process label
    ----  ----------  ------------    ----------------------
     151  3h ago      Running | None  AddAnMultiplyWorkChain
     156  1s ago      Created | None  AddAnMultiplyWorkChain


    Total results: 2

The 'State' column is a concatenation of the ``process_state`` and the ``finish_status`` of the ``WorkCalculation``.
By default, the command will only show active items, i.e. ``WorkCalculations`` that have not yet reached a terminal state.
If you want to also show the nodes in a terminal states, you can use the ``-a`` flag and call ``verdi work list -a``:

.. code-block:: bash

      PK  Creation    State           Process label
    ----  ----------  ------------    ----------------------
     143  3h ago      Finished | 0    add
     146  3h ago      Finished | 0    multiply
     151  3h ago      Running | None  AddAnMultiplyWorkChain
     156  1s ago      Created | None  AddAnMultiplyWorkChain


    Total results: 4

For more information on the meaning of the 'state' column, please refer to the documentation of the :ref:`process state <process_state>`.
The ``-s`` flag let's you query for specific process states, i.e. issuing ``verdi work list -s created`` will return:

.. code-block:: bash

      PK  Creation    State           Process label
    ----  ----------  ------------    ----------------------
     156  1s ago      Created | None  AddAnMultiplyWorkChain


    Total results: 1

To query for a specific finish status, one can use ``verdi work list -f 0``:

.. code-block:: bash

      PK  Creation    State           Process label
    ----  ----------  ------------    ----------------------
     143  3h ago      Finished | 0    add
     146  3h ago      Finished | 0    multiply


    Total results: 2

This simple tool should give you a good idea of the current status of running workflows and the status of terminated ones.
If you are looking for information about a specific workflow node, the following three commands are at your disposal:

 * ``verdi work report`` gives a list of the log messages attached to the workflow
 * ``verdi work status`` print the call hierarchy of the workflow and status of all its nodes
 * ``verdi calculation show`` print details about the status, inputs, outputs, callers and callees of the workflow

In the following sections, we will explain briefly how the commands work.
For the purpose of example, we will show the output of the commands for a completed ``PwBaseWorkChain`` from the ``aiida-quantumespresso`` plugin, which simply calls a ``PwCalculation``.

verdi work report
-----------------
The developer of a ``WorkChain`` can attach log messages to the workchain at any place within the function body of one of the outline steps through the ``self.report()`` method.
The ``verdi work report`` command will display all the log messages in chronological order:

.. code-block:: bash

    2018-04-08 21:18:51 [164 | REPORT]: [164|PwBaseWorkChain|run_calculation]: launching PwCalculation<167> iteration #1
    2018-04-08 21:18:55 [164 | REPORT]: [164|PwBaseWorkChain|inspect_calculation]: PwCalculation<167> completed successfully
    2018-04-08 21:18:56 [164 | REPORT]: [164|PwBaseWorkChain|results]: workchain completed after 1 iterations
    2018-04-08 21:18:56 [164 | REPORT]: [164|PwBaseWorkChain|on_terminated]: remote folders will not be cleaned

The log message will include a timestamp followed by the level of the log, which is always ``REPORT``.
The second block has the format ``pk|class name|step function name`` detailing information about the workchain itself and the step in which the message was fired.
Finally, the message itself is displayed.
Of course how many messages are logged and how useful they are is up to the workchain development.
In general they can be very useful for a user to understand what has happened during the execution of the workchain, however, one has to realize that each entry is stored in the database, so overuse can unnecessarily bloat the database.


verdi work status
-----------------
One of the more powerful aspect of workchains, is that they can call ``JobCalculations`` and other ``WorkChains`` to create a nested call hierarchy.
If you want to inspect the status of a workchain and all the children that it called, ``verdi work status`` is the go-to tool.
An example output is the following:

.. code-block:: bash

    PwBaseWorkChain <pk=164> [ProcessState.FINISHED] [4:results]
        └── PwCalculation <pk=167> [FINISHED]

The command prints a tree representation of the hierarchical call structure, that recurses all the way down.
In this example, there is just a single ``PwBaseWorkChain`` which called a ``PwCalculation``, which is indicated by it being indented one level.
In addition to the call tree, each node also shows its current process state and for workchains at which step in the outline it is.
This tool can be very useful to inspect while a workchain is running at which step in the outline it currently is, as well as the status of all the children calculations it called.


verdi calculation show
----------------------
Finally, there is a command that displays detailed information about the ``WorkCalculation``, such as its inputs, outputs and the calculations it called and was called by.
Since the ``WorkCalculation`` is a sub class of the ``Calculation`` class, we can use the same command ``verdi calculation show`` that one would use to inspect the details of a ``JobCalculation``.
An example output for a ``PwBaseWorkChain`` would look like the following:

.. code-block:: bash

    Property       Value
    -------------  ------------------------------------
    type           WorkCalculation
    pk             164
    uuid           08bc5a3c-da7d-44e0-a91c-dda9ddcb638b
    label
    description
    ctime          2018-04-08 21:18:50.850361+02:00
    mtime          2018-04-08 21:18:50.850372+02:00
    process state  ProcessState.FINISHED
    finish status  0
    code           pw-v6.1

    Inputs            PK  Type
    --------------  ----  -------------
    parameters       158  ParameterData
    structure        140  StructureData
    kpoints          159  KpointsData
    pseudo_family    161  Str
    max_iterations   163  Int
    clean_workdir    160  Bool
    options          162  ParameterData

    Outputs              PK  Type
    -----------------  ----  -------------
    output_band         170  BandsData
    remote_folder       168  RemoteData
    output_parameters   171  ParameterData
    output_array        172  ArrayData

    Called      PK  Type
    --------  ----  -------------
    CALL       167  PwCalculation

    Log messages
    ---------------------------------------------
    There are 4 log messages for this calculation
    Run 'verdi work report 164' to see them

This overview should give you all the information if you want to inspect a workchains inputs and outputs in closer detail as it provides you with their pk's.


.. _workflow_development:

Workflow development
====================

ISSUE#1130


.. _process_spec:

The process specification
-------------------------

This will explain details of the ``ProcessSpec``.


.. _expose_inputs_outputs:

Exposing inputs and outputs
---------------------------

When creating complex workflows, it is a good idea to split them up into smaller, modular parts. At the lowest level, each workflow should perform exactly one task. These workflows can then be wrapped together by a "parent" workflow to create a larger logical unit.

In order to make this approach manageable, it needs to be as simple as possible to glue together multiple workflows in a larger parent workflow. For this reason, AiiDA provides the *expose* functionality, which will be explained here.

Consider the following example workchain, which simply takes a few inputs and returns them again as outputs:

.. include:: include/snippets/workflows/expose_inputs/child.py
    :code: python

As a first example, we will implement a thin wrapper workflow, which simply forwards its inputs to ``ChildWorkChain``, and forwards the outputs of the child to its outputs:

.. include:: include/snippets/workflows/expose_inputs/simple_parent.py
    :code: python

In the ``define`` method of this simple parent workchain, we use the :meth:`.expose_inputs` and :meth:`.expose_outputs`. This creates the corresponding input and output ports in the parent workchain.

Additionally, AiiDA remembers which inputs and outputs were exposed from that particular workchain class. This is used when calling the child in the ``run_child`` method. The :meth:`~aiida.work.Process.exposed_inputs` method returns a dictionary of inputs that the parent received which were exposed from the child, and so it can be used to pass these on to the child.

Finally, in the ``finalize`` method, we use :meth:`~aiida.work.Process.exposed_outputs` to retrieve the outputs of the child which were exposed to the parent. Using :meth:`~aiida.work.Process.out_many`, these outputs are added to the outputs of the parent workchain.

This workchain can now be run in exactly the same way as the child itself:

.. include:: include/snippets/workflows/expose_inputs/run_simple.py
    :code: python

Next, we will see how a more complex parent workchain can be created by using the additional features of the expose functionality. The following workchain launches two children. These children share the input ``a``, but have different ``b`` and ``c``. The output ``e`` will be taken only from the first child, whereas ``d`` and ``f`` are taken from both children. In order to avoid name conflicts, we need to create a *namespace* for each of the two children, where the inputs and outputs which are not shared are stored. Our goal is that the workflow can be called as follows:

.. include:: include/snippets/workflows/expose_inputs/run_complex.py
    :code: python

This is achieved by the following workflow. In the next section, we will explain each of the steps.

.. include:: include/snippets/workflows/expose_inputs/complex_parent.py
    :code: python

First of all, we want to expose the ``a`` input and the ``e`` output at the top-level. For this, we again use :meth:`.expose_inputs` and :meth:`.expose_outputs`, but with the optional keyword ``include``. This specifies a list of keys, and only inputs or outputs which are in that list will be exposed. So by passing ``include=['a']`` to :meth:`.expose_inputs`, only the input ``a`` is exposed.

Additionally, we want to expose the inputs ``b`` and ``c`` (outputs ``d`` and ``f``), but in a namespace specific for each of the two children. For this purpose, we pass the ``namespace`` parameter to the expose functions. However, since we now shouldn't expose ``a`` (``e``) again, we use the ``exclude`` keyword, which specifies a list of keys that will not be exposed.

When calling the children, we again use the :meth:`~aiida.work.Process.exposed_inputs` method to forward the exposed inputs. Since the inputs ``b`` and ``c`` are now in a specific namespace, we need to pass this namespace as an additional parameter. By default, :meth:`~aiida.work.Process.exposed_inputs` will search through all the parent namespaces of the given namespace to search for input, as shown in the call for ``child_1``. If the same input key exists in multiple namespaces, the input in the lowest namespace takes precedence. It's also possible to disable this behavior, and instead search only in the explicit namespace that was passed. This is done by setting ``agglomerate=False``, as shown in the call to ``child_2``. Of course, we then need to explicitly pass the input ``a``.

Finally, we use :meth:`~aiida.work.Process.exposed_outputs` and :meth:`~aiida.work.Process.out_many` to forward the outputs of the children to the outputs of the parent. Again, the ``namespace`` and ``agglomerate`` options can be used to select which outputs are returned by the :meth:`~aiida.work.Process.exposed_outputs` method.

.. _serialize_inputs:

Automatic input serialization
-----------------------------

Quite often, inputs which are given as Python data types need to be cast to the corresponding AiiDA type before passing them to a workflow. Doing this manually can be cumbersome, so you can define a function which does this automatically when defining the input spec. This function, passed as ``serialize_fct`` parameter to ``spec.input``, is invoked if the given input is *not* already an AiiDA type.

For inputs which are stored in the database (``non_db=False``), the serialization function should return an AiiDA data type. For ``non_db`` inputs, the function must be idempotent because it might be applied more than once.

The following example workchain takes three inputs ``a``, ``b``, ``c``, and simply returns the given inputs. The :func:`.to_aiida_type` function is used as serialization function.

.. include:: serialize_examples/serialize_workchain.py
    :code: python

This workchain can now be called with native Python types, which will automatically converted to AiiDA types by the :func:`.to_aiida_type` function. Note that the module which defines the corresponding AiiDA type must be loaded for it to be recognized by :func:`.to_aiida_type`.

.. include:: serialize_examples/run_serialize.py
    :code: python

Of course, you can also use the serialization feature to perform a more complex serialization of the inputs.
