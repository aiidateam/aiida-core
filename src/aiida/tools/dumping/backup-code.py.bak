# Could also be a more general CollectionDumper class, actually

import contextlib
from aiida.common import timezone
from aiida.orm import CalculationNode, Code, Computer, Group, QueryBuilder, StructureData, User, WorkflowNode
from typing import List
from aiida.tools.dumping.utils import _validate_make_dump_path, get_nodes_from_db
from pathlib import Path
from aiida.tools.dumping.processes import ProcessDumper
from aiida.tools.dumping.abstract import AbstractDumper

# DEFAULT_ENTITIES_TO_DUMP = [WorkflowNode, StructureData, User, Code, Computer]
DEFAULT_ENTITIES_TO_DUMP = [CalculationNode, WorkflowNode]  # , StructureData, User, Code, Computer]

# from aiida.common.utils import str_timedelta


class GroupDumper(AbstractDumper):
    def __init__(self, entities_to_dump: List | None = None, **kwargs) -> None:
        super().__init__(self, **kwargs)
        if entities_to_dump is None:
            self.entities_to_dump = DEFAULT_ENTITIES_TO_DUMP

        from aiida.manage import get_manager

        self.profile = get_manager().get_profile()

    def dump(self, group):
        self.last_dumped = timezone.now()

        try:
            group_name = group.label
        except AttributeError:
            group_name = group

        self.parent_path = Path(f'group-dump_{self.profile.name}_{group_name}_{self.last_dumped.strftime("%Y-%m-%d")}')
        self.hidden_aiida_path = self.parent_path / '.aiida-dump'

        # First dump empty in default, hidden AiiDA dumping directory
        # Then create the symlinking

        print('GROUP', group)
        for entity in self.entities_to_dump:
            group_nodes = get_nodes_from_db(aiida_node_type=entity, with_group=group, flat=True)

            print('_DUMP_TO_HIDDEN(SELF, AIIDA_ENTITY, AIIDA_NODES)')
            print(type(entity), entity, len(group_nodes))

            # print("ABC", aiida_entity==CalculationNode)
            if entity==CalculationNode:
                print('SELF._DUMP_CALCULATIONS_HIDDEN', len(group_nodes))
                self._dump_calculations_hidden(calculations=group_nodes)

            if entity==WorkflowNode:
                print('SELF._DUMP_WORKFLOWS_HIDDEN', len(group_nodes))
                self._dump_workflows_hidden(workflows=group_nodes)

    def _dump_calculations_hidden(self, calculations):
        # ? Dump only top-level workchains, as that includes sub-workchains already

        for calculation in calculations:

            # ? Hardcode overwrite=True for now
            calculation_dumper = ProcessDumper(overwrite=True)

            calculation_dump_path = self.hidden_aiida_path / 'calculations' / calculation.uuid
            print(calculation_dump_path)

            # if not self.dry_run:
            with contextlib.suppress(FileExistsError):
                calculation_dumper.dump(process_node=calculation, output_path=calculation_dump_path)


            # # To make development quicker
            # if iworkflow_ > 1:
            #     break

    def _dump_workflows_hidden(self, workflows, only_parents: bool = True):
        # ? Dump only top-level workchains, as that includes sub-workchains already

        for iworkflow_, workflow in enumerate(workflows):
            # if only_parents and workflow.caller is not None:
            #     continue

            # ? Hardcode overwrite=True for now
            workflow_dumper = ProcessDumper(overwrite=True)

            workflow_dump_path = self.hidden_aiida_path / 'workflows' / workflow.uuid
            print(workflow_dump_path)

            # if not self.dry_run:
            with contextlib.suppress(FileExistsError):
                workflow_dumper.dump(process_node=workflow, output_path=workflow_dump_path)

            # self.entity_counter_dictionary[WorkflowNode.__name__] += 1

            # # To make development quicker
            # if iworkflow_ > 1:
            #     break

    # if entities is not None and "groups" in entities:

    #     if dump_data:
    #         # process_qb = orm.QueryBuilder()
    #         # process_qb.append(orm.ProcessNode).all()
    #         if entities is not None and "groups" in entities:
    #             # Dynamically add groups to the query
    #             group_filters = entities["groups"]

    #             # If multiple groups are provided, we need to make sure nodes are in any one of them
    #             group_conditions = []

    #             for group in group_filters:
    #                 print('GROUP', group)

    #                 # Apply the 'OR' condition for the groups, so that the nodes are in at least one group
    #                 process_qb = orm.QueryBuilder()
    #                 process_qb.append(orm.Group, filters={'label': group.label}, tag='group')
    #                 process_qb.append(orm.ProcessNode, with_group='group')

    #                 process_collection_dumper = CollectionDumper(
    #                     parent_path=path,
    #                     also_raw=also_raw,
    #                     also_rich=also_rich,
    #                     qb_instance=process_qb,
    #                     **kwargs
    #                 )
    #                 process_collection_dumper.dump()

    #     if dump_processes:
    #             # Dynamically add groups to the query
    #             group_filters = entities["groups"]

    #             # If multiple groups are provided, we need to make sure nodes are in any one of them
    #             group_conditions = []

    #             for group in group_filters:
    #                 # group_conditions.append({"with_group": group})

    #                 # Apply the 'OR' condition for the groups, so that the nodes are in at least one group
    #                 data_qb = orm.QueryBuilder()
    #                 data_qb.append(orm.Group, filters={'label': group.label}, tag='group')
    #                 data_qb.append(orm.ProcessNode, with_group='group')
    #                 # data_qb.append(orm.Data).all()
    #                 # data_qb.add_filter(orm.Data, with_group=group)

    #                 data_collection_dumper = CollectionDumper(
    #                     parent_path=path,
    #                     also_raw=also_raw,
    #                     also_rich=also_rich,
    #                     qb_instance=data_qb,
    #                     **kwargs,
    #                 )
    #                 data_collection_dumper.dump()

    # profile_dumper = ProfileDumper(
    #     profile='verdi-profile-dump_dev_tiny',
    #     full=True,
    #     parent_path=path,
    #     organize_by_groups=True,
    # )
    # profile_dumper.dump()
    # echo.echo_success(f'Data of profile `{profile.name}` mirrored to disk.')

        # def _dump_processes(self):
    #     print(self.should_dump_calculations())
    #     print(self.should_dump_workflows())
        # self._dump_calculations_hidden()
        # self._link_calculations_hidden()
        # self._dump_link_workflows()
        # # logger.report(f'Linking workflows to calculations for group {group_name}...')

        # # Special case in which no `WorkflowNode`s are contained in the group
        #     # logger.report('GROUP 3 DUMP CALCULATIONS')
        #     # if self.entity_counter.get(orm.WorkChainNode, 0):
        #     self._dump_calculations_hidden()
        #     self._link_calculations_hidden()

                # Special case in which no workflows are contained in the group, but calculations
        # or (
        #     sum(
        #         self.entity_counter.get(orm_process_class, 0)
        #         for orm_process_class in [
        #             orm.WorkChainNode,
        #             orm.WorkFunctionNode,
        #         ]
        #     )
        #     == 0
        #     and sum(
        #         self.entity_counter.get(orm_process_class, 0)
        #         for orm_process_class in [
        #             orm.CalcJobNode,
        #             orm.CalcFunctionNode,
        #         ]
        #     )
        #     > 0
        # )